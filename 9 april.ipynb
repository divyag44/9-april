{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd46a4e5-a5bb-4848-a4cc-5495e74b8f7e",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700f13a-76ee-4be8-88e6-cd8e67352598",
   "metadata": {},
   "source": [
    "## Bayes' theorem is a fundamental concept in probability theory that describes the probability of an event based on prior knowledge or conditions related to the event. It is named after the Reverend Thomas Bayes, who formulated the theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540c5f5-b417-4e6f-a5b2-65adfd3c8f34",
   "metadata": {},
   "source": [
    "## Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5ea1a-92b4-4db3-84b8-f7915b216a0f",
   "metadata": {},
   "source": [
    "## Bayes' theorem can be summarized with the following formula:\n",
    "\n",
    "\\[ P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "where:\n",
    "- \\( P(A | B) \\) is the posterior probability of event \\( A \\) given \\( B \\).\n",
    "- \\( P(B | A) \\) is the likelihood of event \\( B \\) given \\( A \\).\n",
    "- \\( P(A) \\) is the prior probability of event \\( A \\).\n",
    "- \\( P(B) \\) is the total probability of event \\( B \\) (often expressed as the marginal likelihood)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c4bf2-a80c-4429-9905-bf4613faaa94",
   "metadata": {},
   "source": [
    "## Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d54c5-803a-4c96-8a6d-13292aba3665",
   "metadata": {},
   "source": [
    "## Bayes' theorem is used in practice to:\n",
    "- Update beliefs or probabilities based on new evidence or data.\n",
    "- Make predictions or decisions under uncertainty.\n",
    "- Formulate Bayesian statistical models for various applications in fields such as machine learning, healthcare, finance, and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1e5fb-4308-45ad-84d0-51dbb30475f5",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7fb09-e9c2-4c68-b8ac-3f3b1747202d",
   "metadata": {},
   "source": [
    "## Bayes' theorem mathematically connects conditional probabilities. It provides a way to compute the probability of an event \\( A \\) given the occurrence of another event \\( B \\), using the conditional probability of \\( B \\) given \\( A \\) along with the prior probabilities of \\( A \\) and \\( B \\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c3a6d-09ae-44ae-b817-0f0ec80f3447",
   "metadata": {},
   "source": [
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a305664-1819-4231-87bc-f06877a32118",
   "metadata": {},
   "source": [
    "## Choosing the type of Naive Bayes classifier for a given problem depends on several factors:\n",
    "\n",
    "1. **Nature of the Data:**\n",
    "   - **Gaussian Naive Bayes:** Suitable for continuous data where features follow a Gaussian distribution.\n",
    "   - **Multinomial Naive Bayes:** Appropriate for discrete data (e.g., word counts in text classification).\n",
    "   - **Bernoulli Naive Bayes:** Suitable for binary or boolean features (e.g., presence or absence of a feature).\n",
    "\n",
    "2. **Size of the Dataset:**\n",
    "   - **Gaussian and Multinomial Naive Bayes:** Often perform well even with smaller datasets.\n",
    "   - **Bernoulli Naive Bayes:** May require larger datasets due to its assumptions about binary features.\n",
    "\n",
    "3. **Feature Independence Assumption:**\n",
    "   - **Naive Bayes classifiers assume feature independence** within each class. This assumption might not hold in some cases, affecting performance.\n",
    "\n",
    "4. **Application Domain:**\n",
    "   - Consider the specific requirements and characteristics of the problem domain. For example, text classification often uses Multinomial Naive Bayes due to the nature of word frequency distributions.\n",
    "\n",
    "5. **Experimental Evaluation:**\n",
    "   - It's beneficial to experiment with different types of Naive Bayes classifiers and evaluate their performance using cross-validation or other validation methods.\n",
    "\n",
    "In summary, the choice of Naive Bayes classifier depends on the data's distribution (continuous, discrete, binary), the size of the dataset, the independence assumption of features, and the specific requirements of the application domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a90562-005d-47b7-83b5-87c3d4c5f90f",
   "metadata": {},
   "source": [
    "## Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde71a3-a999-4546-a797-4f6e3bb49701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
